_BASE_: ../DVIS_Offline_R50.yaml
MODEL:
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  WEIGHTS: "./output/output_DVIS_Offline_SwinL_YTVIS2023_1(40000-19)_2(40000-21-23)_3(40000-23-0.000015)_4(tiaocan)/model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 200   #原200
    TRAIN_NUM_POINTS: 12544   #原12544
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0001
  STEPS: (50,)
  MAX_ITER: 5000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.05    #原0.05

INPUT:
  MIN_SIZE_TRAIN: (360, 480, 600)  #原(360, 480, 600)
  MAX_SIZE_TRAIN: 1024  #原1024
  MIN_SIZE_TEST: 480    #原480
  PSEUDO:
    MIN_SIZE_TRAIN: (360, 480, 600)

DATASETS:
  DATASET_NEED_MAP: [False]
  DATASET_TYPE: ['video_instance']
  DATASET_TYPE_TEST: ['video_instance', ]
  # The categories of all datasets will be mapped to the categories of the last dataset
  DATASET_RATIO: [1.0]
  TRAIN: ("ytvis_2023_train",)
  TEST: ("ytvis_2023_val",)

OUTPUT_DIR: './output/wuyongwenjian'